# **DBT Design**

## **1\. dbt Conventions**

To ensure consistency, discoverability, and reliable automation across environments, all dbt models follow strict naming and tagging conventions:

### Naming Conventions

- **Bronze models**: Prefix with `bronze_` (e.g., `bronze_orders`, `bronze_customers`)  
- **Silver models**: Prefix with `silver_` (e.g., `silver_orders_enriched`)  
- **Gold models**: Prefix with `gold_` (e.g., `gold_sales_summary`)

This ensures that even when schema context is lost (e.g., cross-schema queries, exports to Fabric/Power BI), model lineage is immediately clear.

### Schema Conventions

- **Bronze models**: Deployed to schema `bronze`  
- **Silver models**: Deployed to schema `silver`  
- **Gold models**: Deployed to schema `gold`

Schemas \+ prefixes together ensure redundancy and future-proofing for domain-level extensions (e.g., `bronze_marketing`, `gold_finance`).

### Tagging Conventions

- **Bronze models**: `tags: ["bronze"]`  
- **Silver models**: `tags: ["silver"]`  
- **Gold models**: `tags: ["gold"]`  
- **Domain-specific tags** may be added (e.g., `["bronze", "sales"]`)

Tags are used by:

- Cosmos DAGs to determine execution order.  
- CI/CD pipelines to selectively run/validate subsets of models.  
- Observability tooling for lineage, cost, and performance reporting.

### File & Folder Conventions

- `models/bronze/bronze_{source_table}.sql`  
- `models/silver/silver_{business_entity}.sql`  
- `models/gold/gold_{analytical_output}.sql`

All autogenerated Bronze models are stored in:

- `models/bronze/generated/`

### Macros

- Platform-provided macros: `/macros/platform/` (do not modify).  
- Client-authored macros: `/macros/custom/`.  
- Macros must be documented with parameters, defaults, and examples.

### Example

```
version: 2

models:
  - name: bronze_orders
    description: "Raw orders ingested from Shopify"
    tags: ["bronze", "shopify"]
    columns:
      - name: order_id
        tests:
          - not_null
          - unique
```

### Platform-Provided Test Macros

Platform provides standardized test macros in `/macros/platform/` that ensure data quality across Bronze ingestion:

- **`test_bronze_integrity()`** \- Validates all ETL control columns (`_integration_key`, `_ingestion_timestamp`, `_update_timestamp`, `_job_run_id`) exist and are populated  
- **`test_watermark_progression()`** \- Ensures `_ingestion_timestamp` is monotonically increasing for incremental loads  
- **`test_integration_key_valid()`** \- Validates `_integration_key` format and ensures no null placeholders

These macros are:

- Platform-managed (do not modify)  
- Automatically applied to Bronze models during CI generation  
- Available for customer reuse in Silver/Gold models via `{{ test_bronze_integrity(model_name) }}`

## **2\. dbt Configuration**

dbt configuration is split into two parts: **profiles** and the **project definition**.Both are managed via **Jinja templates** to ensure portability, environment isolation, and consistency across dev, test, and prod.

### dbt Profiles (`profiles.yml.j2`)

- Stored in the repo under `/dbt/profiles/profiles.yml.j2`.  
- Defines connection details to Fabric SQL endpoints or other data stores.  
- Uses secrets for sensitive values (e.g., host, username, password).  
- Example variables:  
  - `FABRIC_SQL_ENDPOINT_DEV`  
  - `FABRIC_SQL_ENDPOINT_PROD`  
- **Principles:**  
  - Never commit rendered `profiles.yml` to Git.  
  - CI validates templates with mock values; CD renders real values from Key Vault/secret stores.  
  - At runtime, the template is rendered to `~/.dbt/profiles.yml`.

### dbt Project (`dbt_project.yml.j2`)

- Stored in the repo root under `/dbt/dbt_project.yml.j2`.  
- Defines dbt’s logical organization:  
  - **Model paths** (bronze, silver, gold).  
  - **Schema naming conventions** (e.g., `brz_`, `slv_`, `gld_` prefixes).  
  - **Tags** for categorization (layer, source system, domain).  
  - **Materialization defaults** (incremental, table, view).  
- Uses environment-driven variables for schema names and prefixes.  
- **Principles:**  
  - Schema prefixes enforce consistency:  
    - Bronze → `brz_*`  
    - Silver → `slv_*`  
    - Gold → `gld_*`  
  - Tags enable selective runs (e.g., `dbt run --select tag:shopify`).  
  - CI validates schema prefixes and tag usage; CD enforces them at deployment.

### dbt Project Storage

Storage accounts defined in Infrastructure Design Section 4\.

**Code Repository:**

- Containers:  
  - `models/`: dbt model SQL files  
  - `macros/`: Custom and platform macros  
  - `seeds/`: Static reference data

**Documentation:**

- Storage Account: `{customer}-{env}-dbt-st-docs`  
- Container: `$web` (static website hosting)  
- Access: Private endpoint only

**DAG Artifacts:**

- Storage Account: `{customer}-{env}-airflow-st-dags`  
- Containers:  
  - `dags/`: Cosmos-generated DAGs  
  - `manifests/`: dbt manifest.json files

## **3\. CI/CD Workflow for dbt Configs**

**CI (Validation):**

- Lint and validate both `profiles.yml.j2` and `dbt_project.yml.j2`.  
- Render with mock values to confirm templates compile.  
- Run `dbt parse` and `dbt compile` with temp configs.  
- Fail fast if any unresolved Jinja variable or schema mismatch is detected.

**CD (Deployment):**

- Secrets resolved from secret stores (Key Vault, GitHub Actions secrets, or Azure DevOps variable groups).  
- Templates are rendered with real values:  
  - `profiles.yml.j2` → `~/.dbt/profiles.yml`  
  - `dbt_project.yml.j2` → `dbt_project.yml` in the working directory  
- dbt is executed against the rendered configs:  
  - `dbt run`, `dbt test`, and optionally `dbt docs generate`.

**Ephemeral Render Principle:**

- Rendered configs exist only in the CD runtime environment.  
- They are never committed back to Git.

**Alignment with Infrastructure**

- All environment-specific values (endpoints, schema names, resource groups) are provisioned in infrastructure code (Terraform or equivalent).  
- dbt configs pull from the same source of truth as the rest of the platform.  
- This ensures that dbt runtime settings always match the deployed infrastructure.

## **4\. dbt Template Structures**

This section provides the concrete template structures for `profiles.yml.j2` and `dbt_project.yml.j2` that are referenced throughout the dbt Design document.

### **profiles.yml.j2 Template**

The profiles template defines connection configurations for different environments. It's stored at `/dbt/profiles/profiles.yml.j2` in the service central repository and is rendered during CD deployment.

```
# profiles.yml.j2 - dbt profile template for Fabric connection
# This template is rendered with values from Key Vault and terraform outputs

{{ customer_name }}_fabric:
  target: {{ environment }}
  outputs:
    dev:
      type: fabric
      driver: 'ODBC Driver 17 for SQL Server'
      server: {{ FABRIC_SQL_ENDPOINT_DEV }}
      port: 1433
      database: {{ FABRIC_DATABASE_DEV }}
      schema: dbo
      authentication: ActiveDirectoryMsi
      client_id: {{ AZURE_CLIENT_ID }}  # data_platform managed identity
      encrypt: true
      trust_cert: true
      threads: 4
      keepalives_idle: 0
      query_timeout: 0
      
    prod:
      type: fabric
      driver: 'ODBC Driver 17 for SQL Server'
      server: {{ FABRIC_SQL_ENDPOINT_PROD }}
      port: 1433
      database: {{ FABRIC_DATABASE_PROD }}
      schema: dbo
      authentication: ActiveDirectoryMsi
      client_id: {{ AZURE_CLIENT_ID }}  # data_platform managed identity
      encrypt: true
      trust_cert: true
      threads: 8
      keepalives_idle: 0
      query_timeout: 0
```

### **dbt\_project.yml.j2 Template**

The project template defines the dbt project structure, model configurations, and layer-specific settings. It's stored at `/dbt/dbt_project.yml.j2` and ensures consistency across all medallion layers.

```
# dbt_project.yml.j2 - dbt project configuration template
# Enforces medallion architecture conventions and naming standards

name: '{{ customer_name }}_data_platform'
version: '1.0.0'
config-version: 2

# Profile selection - matches the profile name in profiles.yml
profile: '{{ customer_name }}_fabric'

# Project paths
model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

target-path: "target"
clean-targets:
  - "target"
  - "dbt_packages"

# Model configurations by layer
models:
  {{ customer_name }}_data_platform:
    # Bronze layer - raw data ingestion
    bronze:
      +materialized: incremental
      +incremental_strategy: merge
      +unique_key: _integration_key
      +on_schema_change: fail
      +tags: ["bronze", "{{ environment }}"]
      +schema: bronze
      +pre-hook: "{{ log_model_start() }}"
      +post-hook: "{{ log_model_end() }}"
      
      # Dynamic source configurations
      {% for source in sources %}
      {{ source.name }}:
        +tags: ["bronze", "{{ source.name }}"]
        +schema: bronze_{{ source.name }}
      {% endfor %}
    
    # Silver layer - business logic and conforming
    silver:
      +materialized: incremental
      +on_schema_change: sync_all_columns
      +tags: ["silver", "{{ environment }}"]
      +pre-hook: "{{ log_model_start() }}"
      +post-hook: "{{ log_model_end() }}"
      
      # Domain-specific schemas
      customer:
        +schema: silver_customer
        +tags: ["silver", "customer_domain"]
      
      product:
        +schema: silver_product
        +tags: ["silver", "product_domain"]
        
      sales:
        +schema: silver_sales
        +tags: ["silver", "sales_domain"]
    
    # Gold layer - analytics and reporting
    gold:
      +materialized: table
      +tags: ["gold", "{{ environment }}"]
      +pre-hook: "{{ log_model_start() }}"
      +post-hook: "{{ log_model_end() }}"
      
      # Product-specific schemas
      marketing:
        +schema: gold_marketing
        +tags: ["gold", "marketing"]
        
      finance:
        +schema: gold_finance
        +tags: ["gold", "finance"]
        
      executive:
        +schema: gold_executive
        +tags: ["gold", "executive"]

# Test configurations
tests:
  {{ customer_name }}_data_platform:
    +store_failures: true
    +store_failures_as: table
    +schema: test_results
    +severity: warn
    +error_if: ">10"
    +warn_if: ">0"
    
    bronze:
      +severity: warn
      +store_failures: false  # Don't store Bronze test failures
      
    silver:
      +severity: error
      +error_if: ">5"
      +store_failures: true  # Store for debugging
      
    gold:
      +severity: error
      +error_if: ">0"
      +store_failures: true  # Store for debugging

# Test severity configurations
tests:
  {{ customer_name }}_data_platform:
    +severity: warn
    +error_if: ">10"
    +warn_if: ">0"
    
    bronze:
      +severity: warn
      
    silver:
      +severity: error
      +error_if: ">5"
      
    gold:
      +severity: error
      +error_if: ">0"

# Variable definitions
vars:
  environment: '{{ environment }}'
  customer_name: '{{ customer_name }}'
  freshness_threshold_hours: {{ freshness_threshold_hours | default(24) }}
  enable_data_quality_checks: {{ enable_data_quality_checks | default(true) }}
  batch_size: {{ batch_size | default(10000) }}
  log_level: '{{ log_level | default("info") }}'

# Query comments for warehouse monitoring
query-comment:
  comment: "dbt-{{ customer_name }}-{{ environment }}-{{ run_started_at }}"
  append: true
```

### **Variable Resolution Chain**

The template variables are resolved from multiple sources during the CD deployment process:

#### **Infrastructure-Derived Variables** (from Terraform outputs → Key Vault)

| Variable | Source | Example Value |
| :---- | :---- | :---- |
| `FABRIC_SQL_ENDPOINT_DEV` | data-platform module output | `workspace123.sql.azuresynapse.net` |
| `FABRIC_SQL_ENDPOINT_PROD` | data-platform module output | `workspace456.sql.azuresynapse.net` |
| `FABRIC_DATABASE_DEV` | data-platform module output | `lakehouse_dev` |
| `FABRIC_DATABASE_PROD` | data-platform module output | `lakehouse_prod` |
| `AZURE_CLIENT_ID` | security module output | `12345678-1234-1234-1234-123456789012` |
| `AZURE_TENANT_ID` | Azure subscription | `87654321-4321-4321-4321-210987654321` |

#### **Fabric Resource Variables** (from CD pipeline → Key Vault)

| Variable | Source | Created By |
| :---- | :---- | :---- |
| `FABRIC_WORKSPACE_ID` | Fabric REST API response | Fabric SP during deployment |
| `FABRIC_LAKEHOUSE_ID` | Fabric REST API response | Fabric SP during deployment |
| `FABRIC_SQL_ENDPOINT_{ENV}` | Derived from workspace | Post-workspace creation |

**Dependency:** These variables only exist AFTER Fabric SP creates resources in CD pipeline.

#### **Configuration File Variables** (from terraform.tfvars)

| Variable | Config File | Example Value |
| :---- | :---- | :---- |
| `customer_name` | terraform.tfvars | `contoso` |
| `environment` | terraform.tfvars | `dev` or `prod` |
| `sources` | Derived from airbyte\_sources/\*.yml | `[{name: "salesforce"}, {name: "shopify"}]` |

#### **dbt-Specific Variables** (from config/06\_dbt.tfvars)

| Variable | Default | Purpose |
| :---- | :---- | :---- |
| `freshness_threshold_hours` | 24 | SLA for data freshness |
| `enable_data_quality_checks` | true | Toggle data quality tests |
| `batch_size` | 10000 | Incremental processing batch size |
| `log_level` | info | dbt logging verbosity |

### **Template Rendering Process**

The templates are rendered during the CD pipeline execution:

```shell
# Step 1: Retrieve secrets from Key Vault
FABRIC_ENDPOINT=$(az keyvault secret show \
  --vault-name ${CUSTOMER}-${ENV}-security-kv \
  --name fabric-sql-endpoint-${ENV} \
  --query value -o tsv)

FABRIC_DATABASE=$(az keyvault secret show \
  --vault-name ${CUSTOMER}-${ENV}-security-kv \
  --name fabric-database-${ENV} \
  --query value -o tsv)

MANAGED_IDENTITY=$(az keyvault secret show \
  --vault-name ${CUSTOMER}-${ENV}-security-kv \
  --name data-platform-mi-client-id \
  --query value -o tsv)

# Step 2: Render profiles.yml
jinja2 /templates/profiles.yml.j2 \
  -D customer_name="${CUSTOMER_NAME}" \
  -D environment="${ENVIRONMENT}" \
  -D FABRIC_SQL_ENDPOINT_DEV="${FABRIC_ENDPOINT}" \
  -D FABRIC_DATABASE_DEV="${FABRIC_DATABASE}" \
  -D AZURE_CLIENT_ID="${MANAGED_IDENTITY}" \
  > ~/.dbt/profiles.yml

# Step 3: Render dbt_project.yml
jinja2 /templates/dbt_project.yml.j2 \
  -D customer_name="${CUSTOMER_NAME}" \
  -D environment="${ENVIRONMENT}" \
  -D sources="${SOURCES_JSON}" \
  -D freshness_threshold_hours="${FRESHNESS_THRESHOLD}" \
  -D enable_data_quality_checks="${ENABLE_DQ}" \
  -D batch_size="${BATCH_SIZE}" \
  -D log_level="${LOG_LEVEL}" \
  > dbt_project.yml

# Step 4: Execute dbt with rendered configs
dbt deps
dbt run --target ${ENVIRONMENT}
dbt test --target ${ENVIRONMENT}
```

### **Secret Storage Pattern**

All sensitive connection information follows this flow:

```
Terraform Deployment
    ↓
Creates Fabric Workspace & SQL Endpoint
    ↓
Outputs: endpoint URL, database name
    ↓
CD Pipeline captures outputs
    ↓
Stores in Key Vault as secrets:
  - fabric-sql-endpoint-{env}
  - fabric-database-{env}
  - fabric-workspace-{env}
    ↓
dbt CD retrieves secrets
    ↓
Renders templates with actual values
    ↓
dbt executes with connection info
```

### **Template Ownership and Update Model**

**Critical Understanding:**

- **Platform owns templates** \- Jinja2 files distributed via artifacts, read-only for clients  
- **Clients own configuration** \- Update only terraform.tfvars and config/\*.tfvars files  
- **CD owns rendering** \- Pipeline renders templates with client config, creates ephemeral files  
- **Nobody edits rendered files** \- They exist only during pipeline execution

**Client Update Path:** When clients need to change dbt behavior, they:

1. Update values in `config/06_dbt.tfvars` (e.g., batch\_size, threads)  
2. Commit and push changes  
3. CD pipeline renders new files with updated values  
4. dbt executes with new configuration

Clients NEVER directly edit:

- `/dbt/profiles/profiles.yml.j2` (platform template)  
- `/dbt/dbt_project.yml.j2` (platform template)  
- `~/.dbt/profiles.yml` (rendered file)  
- `dbt_project.yml` (rendered file)

### **Template Validation**

Templates are validated at multiple stages:

#### **CI Validation** (with mock values)

```
# ci-mock-values.yml
customer_name: "test_customer"
environment: "ci"
FABRIC_SQL_ENDPOINT_DEV: "mock-workspace.sql.azuresynapse.net"
FABRIC_DATABASE_DEV: "mock_lakehouse"
AZURE_CLIENT_ID: "00000000-0000-0000-0000-000000000000"
sources:
  - name: "mock_source"
```

#### **Validation Commands**

```shell
# Render with mock values
jinja2 profiles.yml.j2 -D @ci-mock-values.yml > test_profiles.yml

# Validate YAML syntax
yamllint test_profiles.yml

# Validate dbt can parse
dbt parse --profiles-dir . --profile test_customer --target ci
```

### **Environment-Specific Variables**

The template system uses environment-specific variables that are injected during the rendering process. These are not post-deployment overrides but rather values that customize the template at render time.

**Variable Categories:**

| Category | Examples | Purpose |
| :---- | :---- | :---- |
| **Performance Tuning** | `DBT_THREADS`, `DBT_QUERY_TIMEOUT` | Dev uses fewer threads (4) vs Prod (8) |
| **Resource Sizing** | `batch_size`, `query_timeout` | Different limits per environment |
| **Feature Flags** | `enable_data_quality_checks` | Enable/disable features per environment |
| **Logging Levels** | `log_level` | Debug in dev, info in prod |

**Important Note:** These variables are applied during template rendering in the CD pipeline. Once rendered, the profiles.yml and dbt\_project.yml files contain final values. Manual editing of rendered files is discouraged as it breaks the infrastructure-as-code principle.

### **Template Versioning**

Templates are versioned alongside the platform artifacts:

- Templates are part of the platform bundle distributed via Azure Artifacts  
- Version controlled with semantic versioning (e.g., `v3.1.0`)  
- Changes to templates trigger a MINOR version bump  
- Breaking changes to template structure trigger a MAJOR version bump

### **Customer Customization Points**

While templates are platform-managed, customers can customize through:

1. **Variable Injection**: Via `config/06_dbt.tfvars`  
2. **Model-Level Configuration**: Override defaults in individual model files  
3. **Custom Macros**: Add business logic in `/macros/custom/`  
4. **Schema Extensions**:  
   - Silver domains: Define in model config (e.g., `{{ config(schema='silver_customer') }}`)  
   - Gold products: Define in model config (e.g., `{{ config(schema='gold_marketing') }}`)

Example of client-defined domain schema in a Silver model:

```sql
-- models/silver/customer_enriched.sql
{{ config(
    schema='silver_customer',
    tags=['silver', 'customer_domain']
) }}

SELECT ...
```

